{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Metrics:\n",
      "Model: Logistic Regression\n",
      "Accuracy: 0.9722\n",
      "Precision: 0.9726\n",
      "Recall: 0.9722\n",
      "F1 Score: 0.9723\n",
      "Confusion Matrix:\n",
      "[[33  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 28  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 33  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 33  0  1  0  0  0  0]\n",
      " [ 0  1  0  0 45  0  0  0  0  0]\n",
      " [ 0  0  1  0  0 44  1  0  0  1]\n",
      " [ 0  0  0  0  0  1 34  0  0  0]\n",
      " [ 0  0  0  0  0  1  0 33  0  0]\n",
      " [ 0  0  0  0  0  1  0  0 29  0]\n",
      " [ 0  0  0  1  0  0  0  0  1 38]]\n",
      "AUC: 0.9989\n",
      "\n",
      "Model: Decision Tree\n",
      "Accuracy: 0.8639\n",
      "Precision: 0.8672\n",
      "Recall: 0.8639\n",
      "F1 Score: 0.8638\n",
      "Confusion Matrix:\n",
      "[[29  0  0  0  2  1  0  1  0  0]\n",
      " [ 1 21  1  0  3  0  0  1  0  1]\n",
      " [ 0  0 27  3  1  0  0  1  1  0]\n",
      " [ 0  0  0 29  0  1  0  1  2  1]\n",
      " [ 0  0  0  0 41  2  2  1  0  0]\n",
      " [ 0  0  2  0  1 43  0  0  1  0]\n",
      " [ 0  0  0  0  1  0 34  0  0  0]\n",
      " [ 0  0  0  3  1  0  0 30  0  0]\n",
      " [ 0  2  0  1  0  1  0  0 23  3]\n",
      " [ 0  0  0  2  1  0  1  1  1 34]]\n",
      "AUC: 0.9240\n",
      "\n",
      "Model: Random Forest\n",
      "Accuracy: 0.9694\n",
      "Precision: 0.9705\n",
      "Recall: 0.9694\n",
      "F1 Score: 0.9695\n",
      "Confusion Matrix:\n",
      "[[32  0  0  0  1  0  0  0  0  0]\n",
      " [ 0 28  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 33  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 33  0  1  0  0  0  0]\n",
      " [ 0  0  0  0 46  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 45  1  0  0  1]\n",
      " [ 0  0  0  0  0  1 34  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 33  0  1]\n",
      " [ 0  2  0  0  0  1  0  0 27  0]\n",
      " [ 0  0  0  0  1  1  0  0  0 38]]\n",
      "AUC: 0.9996\n",
      "\n",
      "Model: Support Vector Machine\n",
      "Accuracy: 0.9861\n",
      "Precision: 0.9862\n",
      "Recall: 0.9861\n",
      "F1 Score: 0.9861\n",
      "Confusion Matrix:\n",
      "[[33  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 28  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 33  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 34  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 46  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 46  1  0  0  0]\n",
      " [ 0  0  0  0  0  0 35  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 33  0  1]\n",
      " [ 0  0  0  0  0  0  0  0 29  1]\n",
      " [ 0  0  0  0  0  1  0  1  0 38]]\n",
      "AUC: 0.9999\n",
      "\n",
      "Model: K-Nearest Neighbors\n",
      "Accuracy: 0.9861\n",
      "Precision: 0.9862\n",
      "Recall: 0.9861\n",
      "F1 Score: 0.9861\n",
      "Confusion Matrix:\n",
      "[[33  0  0  0  0  0  0  0  0  0]\n",
      " [ 0 28  0  0  0  0  0  0  0  0]\n",
      " [ 0  0 33  0  0  0  0  0  0  0]\n",
      " [ 0  0  0 34  0  0  0  0  0  0]\n",
      " [ 0  0  0  0 46  0  0  0  0  0]\n",
      " [ 0  0  0  0  0 45  1  0  0  1]\n",
      " [ 0  0  0  0  0  0 35  0  0  0]\n",
      " [ 0  0  0  0  0  0  0 33  0  1]\n",
      " [ 0  0  0  0  0  0  0  0 30  0]\n",
      " [ 0  0  0  0  1  1  0  0  0 38]]\n",
      "AUC: 0.9985\n",
      "\n",
      "The best model based on accuracy is: Support Vector Machine\n"
     ]
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "digits = load_digits()\n",
    "X, y = digits.data, digits.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=10000),\n",
    "    \"Decision Tree\": DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Support Vector Machine\": SVC(probability=True),\n",
    "    \"K-Nearest Neighbors\": KNeighborsClassifier()\n",
    "}\n",
    "\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    precision = precision_score(y_test, y_pred, average='weighted')\n",
    "    recall = recall_score(y_test, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    auc = roc_auc_score(y_test, model.predict_proba(X_test), multi_class='ovr', average='weighted')\n",
    "    results[name] = {\"Accuracy\": accuracy, \"Precision\": precision, \"Recall\": recall, \"F1 Score\": f1, \"Confusion Matrix\": cm, \"AUC\": auc}\n",
    "\n",
    "best_model = max(results, key=lambda x: results[x]['Accuracy'])\n",
    "\n",
    "print(\"Evaluation Metrics:\")\n",
    "for name, metrics in results.items():\n",
    "    print(f\"Model: {name}\")\n",
    "    print(f\"Accuracy: {metrics['Accuracy']:.4f}\")\n",
    "    print(f\"Precision: {metrics['Precision']:.4f}\")\n",
    "    print(f\"Recall: {metrics['Recall']:.4f}\")\n",
    "    print(f\"F1 Score: {metrics['F1 Score']:.4f}\")\n",
    "    print(f\"Confusion Matrix:\\n{metrics['Confusion Matrix']}\")\n",
    "    print(f\"AUC: {metrics['AUC']:.4f}\\n\")\n",
    "\n",
    "print(f\"The best model based on accuracy is: {best_model}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Liner Regression\n",
    "\n",
    "strengths: Fast training and prediction\n",
    "\n",
    "Weaknesses: Sensitive to outliers\n",
    "\n",
    "2. Logistic Regression\n",
    "\n",
    "Strengths: Efficient for binary classification tasks\n",
    "\n",
    "Weaknesses: Sensitivity to irrelevant features\n",
    "\n",
    "3. Naive Bayes Classifier\n",
    "\n",
    "Strengths: Performs well with high-dimensional data\n",
    "\n",
    "Weaknesses: May not capture complex relationships between features\n",
    "\n",
    "4. Support Vector Machine (SVM)\n",
    "\n",
    "Strengths: Effective in high-dimensional spaces\n",
    "\n",
    "Weaknesses: Computationally expensive for large datasets\n",
    "\n",
    "5. Decision Trees\n",
    "\n",
    "Strengths: Can handle both numerical and categorical data\n",
    "\n",
    "Weaknesses: Prone to overfitting\n",
    "\n",
    "6. Random Forests\n",
    "\n",
    "Strengths: Combines multiple decision trees to reduce overfitting \n",
    "\n",
    "Weaknesses: May not perform well with highly imbalanced datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Precision:\n",
    "\n",
    "Precision measures the proportion of true positive predictions among all positive predictions made by the model.\n",
    "\n",
    "Formula: Precision = TP / (TP + FP)\n",
    "\n",
    "Importance: Precision is essential when the cost of false positives is high. It indicates the model's ability to avoid false alarms and make accurate positive predictions.\n",
    "\n",
    "2. Recall (Sensitivity):\n",
    "\n",
    "Recall measures the proportion of true positive predictions among all actual positive instances in the dataset.\n",
    "\n",
    "Formula: Recall = TP / (TP + FN)\n",
    "\n",
    "Importance: Recall is crucial when the cost of false negatives is high. It ensures that the model can identify all positive instances and avoid missing important cases.\n",
    "\n",
    "3. Accuracy:\n",
    "\n",
    "Accuracy measures the proportion of correct predictions (both true positives and true negatives) among all predictions made by the model.\n",
    "\n",
    "Formula: Accuracy = (TP + TN) / (TP + TN + FP + FN)\n",
    "\n",
    "Importance: Accuracy provides an overall assessment of the model's correctness. However, it may not be suitable for imbalanced datasets where the classes are unevenly distributed.\n",
    "\n",
    "4. F1 Score:\n",
    "\n",
    "F1 score is the harmonic mean of precision and recall, providing a balanced measure of a model's performance.\n",
    "\n",
    "Formula: F1 Score = 2 * (Precision * Recall) / (Precision + Recall)\n",
    "\n",
    "Importance: F1 score balances both precision and recall, making it useful when there is an uneven class distribution or when both false positives and false negatives are equally important.\n",
    "\n",
    "5. Confusion Matrix:\n",
    "\n",
    "A confusion matrix is a table that summarizes the performance of a classification model by comparing predicted and actual class labels.\n",
    "It consists of four metrics: True Positives (TP), False Positives (FP), True Negatives (TN), and False Negatives (FN).\n",
    "\n",
    "Importance: Confusion matrix provides insights into the types of errors made by the model and helps in understanding its strengths and weaknesses.\n",
    "\n",
    "6. Area Under the ROC Curve (AUC):\n",
    "\n",
    "AUC measures the ability of a model to distinguish between positive and negative instances.\n",
    "The ROC curve is a graphical representation of the trade-off between true positive rate (TPR) and false positive rate (FPR) at various threshold settings.\n",
    "\n",
    "Importance: AUC provides a single scalar value to compare the performance of different models. It is robust to class imbalance and threshold selection.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
